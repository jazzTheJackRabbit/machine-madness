\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{multicol}
\usepackage[style=numeric,backend=bibtex]{biblatex}

\addbibresource{refsKami.bib}

\title{Machine Madness}
\author{
  Amogh Param\\
  704434779\\
  \texttt{aparam@cs.ucla.edu}
  \and
  Sravani Kamisetty\\
  304414410\\
  \texttt{skamisetty@cs.ucla.edu}
}
\date{December 2015}

\begin{document}
    \maketitle
    
    \begin{multicols}{2}
    \section*{Abstract}  
	March Madness is the NCAA Men’s Division I Basketball Championship tournament that happens every March. The tournament is organized by the National Collegiate Athletic Association (NCAA). It has 64 tournament matches. The aim of this project is to come up with a good machine learning based model has the best classification accuracy in predicting the march madness bracket.
   
    \section{Introduction}
    Since 1939, the best colleges and universities across the United States have participated in a yearly tournament called the NCAA Men’s Basketball Championship. This basketball tournament has become one of the most popular and famous sporting tournaments in the United States. Millions of people around the country participate in contests in which the participants make their best guesses on who will win each game throughout the tournament. These types of contests have become so popular that more than 11 million brackets were filled out on ESPN.com in 2014. One billion dollars was even being rewarded to anyone who achieved a ”perfect bracket” (guessed every game correctly). Every game is unpredictable, and the teams that are supposedly the ”better team” sometimes end up losing. This is called an upset in basketball lingo, and happens regularly throughout the tournament. Because of these upsets, it can be difficult to correctly guess the winner of each game. The tournament can be so unpredictable that the time period over which the tournament runs has been termed March Madness. Since there are 64 games played in the NCAA tournament, it is nearly impossible to predict a perfect bracket. High Point Enterprise, a morning paper from North Carolina, stated that ”you have a much greater chance of winning the lottery, shooting a hole-in-one in golf or being struck by lightning”. They estimated that the chances of predicting a perfect bracket are 1 in 9.2 quintillion. It became clear that developing a model that provided perfect win/loss classification was unrealistic, so instead we focused on improving the prediction accuracy of individual games. The problem at hand is not classification of individual teams, but rather predicting the outcome of a match between any two teams. 
    
    \subsection{Objectives}
    Our goal was to identify key factors in predicting NCAA tournament wins and to find a
model that would perform well in the Kaggle competition.
The Kaggle competition had two stages:
\begin{list}{•}{•}
\item Predict outcomes of the 2016 NCAA Tournament
\end{list}
    For each stage we submitted a list $\hat{y}$ of probabilities (values between 0 and 1) that each team in the tournament would defeat every other team in the tournament, regardless of whether this match-up actually occurs. For this year, this was m = 2278 predictions 2. We were judged based on the log-loss L(y|$\hat{y}$), or the predictive binomial deviance, of the games that actually occurred.
    \linebreak 
    \linebreak 
    $L(y|\hat{y}) = -1/n * \sum_{i=1}^{n}[y_i.log(\hat{y_i} + (1-y_i). log(1-\hat{y_i}))]$ where n is the actual number of games played in the tournament (67), $y_i$ is the actual binary outcome of each game, and $\hat{y_i}$ is the corresponding submitted probability. If the opponents in game i are teams A and B, then $\hat{y_i}(A,B)$ is the predicted probability that team A beats team B, and $\hat{y_i}(B,A)=1-\hat{y_i}(A,B)$
   \linebreak
   \linebreak
   The goal is to find a set of predictions $\hat{y}$ that minimizes L(y|$\hat{y}$) for the unknown outcome vector y. This scoring method heavily penalizes being simultaneously confident and wrong. If we say Team A will beat Team B with probability 1 and Team B wins, then our log-loss is infinite (although Kaggle bounded the log-loss function to avoid infinite scores). At the same time, it is important to balance between being too conservative and too confident. If we are too conservative (e.g. $\hat{y} \approx 0.5)$, then we will never accrue points, but if we are too confident, we make ourselves vulnerable to huge losses.\cite{1}

	\section{Challenges}
	\subsection{Upsets}
	Every game is unpredictable, and the teams that are supposedly the ”better team” sometimes end up losing. This
is called an upset in basketball lingo, and happens regularly throughout the tournament. Because of these upsets, it can be difficult to correctly guess the winner of each game. The tournament can be so unpredictable.\cite{2}

	\subsection{Chance of predicting a perfect bracket}
	Since there are 64 games played in the NCAA tournament,
the odds of forecasting a perfect bracket are astronomical. Each game win/lose has a probability of 1/2. The complexity of the bracke prediction is 1/2*1/2..1/2 (63 times) which is 1 in $~approx$ 9.2 quintillion channce. This is lower than the chance of winning a lottery.

	\subsection{Unpredictable events}
	There are multiple events that happen during a match that cannot be predicted. The best example being injury of a key player. A new player being added to a team is one other such example. Playing at home ground vs playing else where sometimes also affects the outcome of the match.
	
	\subsection{Team Dynamics}
	The dynamics of a team change yearly. New players could be added, older key players could be removed. This makes it difficult to compare the performance of a new team to a old team as the logistics and features of an older team do not represent the newer team accurately. 
	
	\section{Data}
	The main source of Data is Kaggle. The data is made availabe as a bunch of .csv files. Kaggle provides regular season wins, losses, point differences, dates, and game locations (home/away) as well as tournament wins, losses, point differences, seeds, and dates of games. This data comes from the sesonal and tournament mactches for the years 2005-2015. \cite{1}. The other important source of data is player level statistics from ESPN.
	
	\subsection{Data Fields}
	The data provided by Kaggle can be broadly classified into tournament level and season level statistics and also by compactness of the data. The most important fields in this dataset which could be potential feature set are listed below.  \cite{1}
	
	This data fields identifying the different seasons included in the historical data, along with certain season-level properties are:

\begin{list}{Field}{}
\item 
"season" - indicates the year in which thetournament was played
\item
"dayzero" - tells you the date corresponding to daynum=0 during that season. 
\item
"region W/X/Y/Z" - by convention, the four regions in the final tournament are always named W, X, Y, and Z.
\end{list}

	The game by game results are represented by the following data fields:
\begin{list}{Field}{}
\item
wteam" - this identifies the id number of the team that won the game
\item
"wscore" - this identifies the number of points scored by the winning team.
\item
"lteam" - this identifies the id number of the team that lost the game.
\item
"lscore" - this identifies the number of points scored by the losing team.
\item
"numot" - this indicates the number of overtime periods in the game, an integer 0 or higher.
\item
"wloc" - this identifies the "location" of the winning team. If the winning team was the home team, this value will be "H".
\item
"wfgm" - field goals made
\item
"wfga" - field goals attempted
\item
"wfgm3" - three pointers made
\item
"wfga3" - three pointers attempted
\item
"wftm" - free throws made
\item
"wfta" - free throws attempted
\item
"wor" - offensive rebounds
\item
"wdr" - defensive rebounds
\item
"wast" - assists
\item
"wto" - turnovers
\item
"wstl" - steals
\item
"wblk" - blocks
\item
"wpf" - personal fouls
\item
"seed" - this is a 3/4-character identifier of the seed, where the first character is either W, X, Y, or Z (identifying the region the team was in) and the next two digits (either 01, 02, ..., 15, or 16) tells you the seed within the region.
\item
"slot" - this uniquely identifies one of the tournament games. For play-in games, it is a three-character string identifying the seed fulfilled by the winning team, such as W16 or Z13. For regular tournament games, it is a four-character string, where the first two characters tell you which round the game is (R1, R2, R3, R4, R5, or R6) and the second two characters tell you the expected seed of the favored team.
\item
"strongseed" - this indicates the expected stronger-seeded team that plays in this game.
\item
"weakseed" - this indicates the expected weaker-seeded team that plays in this game, assuming all favored teams have won so far.
\end{list}

	\subsection{Scale of the Data}
	Kaggle provides data from the NCAA seaons and tournaments between 2005 and 2015. The statistics below give an idea about the scale of the dataset.	
\begin{list}{•}{•}
\item
Number of seasons: 10 seasons
\item
Number of tournaments: 10 tournaments
\item
Number of matches in each season ~ 5000
\item
Number of matches in each tournament ~ 64
\item
Total number of matches in the training set ~ 50,640
\item
Total number of matches in testing set : 64
\item
Total number of columns in the training set/testing set ~ numeber of data fields or features = 25
\end{list}

	\section{Features}
		 
	\end{multicols}  
\end{document}
